# ğŸš€ Internly â€“ Intelligent Job & Internship Finder
Internly is a full-stack Job & Internship Intelligence System that aggregates opportunities from multiple platforms and ranks them using NLP-based relevance scoring.
It helps students and early professionals discover the most relevant roles faster, without manually browsing multiple job portals.

ğŸ” **Search once. Discover smarter.**

ğŸŒ Live Demo

  Backend API (FastAPI)
    ğŸ‘‰ https://your-railway-domain.up.railway.app

  Example Endpoint
    GET /search?role=python

âœ¨ Features

ğŸ” Smart Job Search
  Search by role (e.g., Python Developer, Web Development, Data Science)

ğŸ§  NLP-Based Relevance Scoring
  Jobs are ranked using TF-IDF + cosine similarity

ğŸŒ Multi-Source Aggregation
  Currently supports:

Internshala
  (architecture supports easy extension to other portals)

ğŸ•’ Human-Readable Posting Time
    Displays results like â€œPosted 2 days agoâ€

ğŸ¨ Modern Dark UI
    Card-based grid layout inspired by modern job platforms

ğŸš€ Production Deployment
    Dockerized & deployed on Railway

ğŸ—ï¸ Tech Stack
  Backend
  Python 3.10
  FastAPI
  Uvicorn
  BeautifulSoup4 â€“ Web scraping
  scikit-learn â€“ NLP similarity
  NumPy
  SQLAlchemy (ready for persistence)
  Frontend
  HTML5
  CSS3 (Dark Theme UI)
  Vanilla JavaScript (Fetch API)
  DevOps
  Docker
  Railway (Cloud Deployment)
  Git & GitHub

ğŸ§  System Architecture

  
  User Search Query
          â†“
  Keyword Normalization
          â†“
  Job Scraper (Internshala)
          â†“
  NLP Similarity Engine
          â†“
  Relevance Scoring
          â†“
  Ranked Results API
          â†“
  Frontend Card UI

ğŸ“ Project Structure
  Internly/
  â”œâ”€â”€ backend/
  â”‚   â”œâ”€â”€ main.py          # FastAPI app
  â”‚   â”œâ”€â”€ scraper.py       # Job scraping logic
  â”‚   â”œâ”€â”€ nlp_engine.py    # NLP relevance scoring
  â”‚   â”œâ”€â”€ models.py        # Data models
  â”‚   â””â”€â”€ database.py      # DB setup (optional)
  â”‚
  â”œâ”€â”€ frontend/
  â”‚   â”œâ”€â”€ index.html      
  â”‚
  â”œâ”€â”€ Dockerfile
  â”œâ”€â”€ requirements.txt
  â””â”€â”€ README.md

âš™ï¸ Local Setup
  1ï¸âƒ£ Clone the repository
    git clone https://github.com/your-username/Internly.git
    cd Internly

  2ï¸âƒ£ Install dependencies
    pip install -r requirements.txt

  3ï¸âƒ£ Run the backend
    uvicorn backend.main:app --reload

  Backend runs at:
    http://127.0.0.1:8000

ğŸ³ Docker Setup (Production)
  docker build -t internly .
  docker run -p 8080:8080 internly

ğŸš€ Deployment
  The backend is deployed using Docker on Railway, with dynamic port handling via environment variables.
  Key deployment learnings:
  Proper $PORT expansion using sh -c
  Python version compatibility
  Dependency pinning to avoid NumPy 2.x build issues
  Clean separation of frontend & backend

ğŸ§ª Sample API Response
[
  {
    "title": "Python Development Intern",
    "company": "Winfrox",
    "source": "Internshala",
    "posted": "Posted 2 days ago",
    "score": 0.41,
    "url": "https://internshala.com/..."
  }
]

ğŸ“Œ What I Learned
  Building real-world web scrapers
  Applying NLP for semantic relevance
  Designing REST APIs with FastAPI
  Debugging production Docker deployments
  Handling cloud platform quirks (Railway, Render)
  Writing clean, maintainable project structure

ğŸ”® Future Enhancements

  ğŸ”” Job alerts & notifications

  ğŸ“Š Skill gap analysis

  ğŸ§¾ Resumeâ€“Job matching

  ğŸŒ More job portals

  ğŸ” User accounts & saved searches

  ğŸ‘¤ Author

Sreehari Vinod
Computer Science Student | Python Developer | ML & Full-Stack Enthusiast | Full-Stack Developer | UI Designer

GitHub: https://github.com/OfficialSreehariVinod
LinkedIn: https://linkedin.com/in/sreeharivinodofficial

Rooney Francis
Computer Science Student | UI/UX Designer 

Wordpress: uiron.netlify.app
Github: https://github.com/iamRooney
LinkedIn: https://www.linkedin.com/in/rooney-francis/

â­ Final Note

  This project is built with real deployment constraints, not just local demos.
  Every feature reflects practical engineering decisions â€” scraping limits, NLP tradeoffs, and production debugging.

If youâ€™re reviewing this project:
ğŸ‘‰ Run it. Break it. Improve it. Thatâ€™s how it was designed.
